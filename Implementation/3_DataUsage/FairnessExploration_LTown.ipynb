{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ae674-1a0e-459b-b9dd-11bb5f8673ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "import wntr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e9f10-34f6-491d-adbd-e9b26b02674f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8a571-4ceb-4074-a460-18ac026e3cce",
   "metadata": {},
   "source": [
    "The data frame *df_leaks* holds pressure **residuals** for different times (along rows) and different sensors (along columns '0', '3', '30', ...). Moreover, the sensitive features and columns 'y_group1', 'y_group2' and 'y_group3' are binary labels telling us whether (1) or whether not (0) a leak is active for that time in group j for \"j = 1,2,3\". Additionally, the overall label and column 'y' is a binary label telling uns whether (1) or whether not (0) a leak is active in the WDN in general.\n",
    "Additionally (and differently to the FairnessExploration_Hanoi and FairnessExploration_Hanoi_extended files), the column 'dia' gives information about the leak size.\n",
    "\n",
    "The data frame *df_information* holds information about the leaks appearing in *df_leaks*. Each leak setting has the main characteristics 'node ID' and 'diameter'. \n",
    "Differently to the Hanoi sensor data, the data frame df_information is created based on the data frame df_leaks and not the data frame df_leaks is created based on the data frame df_information. As L-Town is a much larger water distribution network, not each node in the WDN is considered as a leaky node in the data. *df_information* holds information about each existing setting (along rows), such as \n",
    "\n",
    "- 'group' (areal group to which the leaky node belongs to),\n",
    "- 'node ID' (location of the leak, but only placeholders - true node ID might differ),\n",
    "- 'diameter' (size of the leak),\n",
    "- 'setting start ID' (time index in the *df_leaks* at which the setting starts),\n",
    "- 'leak start ID' (time index in the *df_leaks* at which the leak starts),\n",
    "- 'leak end ID' (time index in the *df_leaks* at which the leak ends),\n",
    "- 'setting end ID' (time index in the *df_leaks* at which the setting ends)\n",
    "\n",
    "(along columns).\n",
    "\n",
    "The data frame *df_noleaks* is not available in this setting. As this data frame is only used for visualization, this is not an issue. \n",
    "\n",
    "**Important**: Note that due to the fact the data frame df_leaks holds pressure residuals instead of pressure measurements, the regression part can be skipped in this notebook. Also due to the fact that there is no df_noleaks data frame, most of the visualizations regarding the pressure (residual) measurements are not displayed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1a4a5-d4d4-42e5-8330-67a4949e2a3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LeakInformation(df):\n",
    "    \n",
    "    # ----- leak information in data frame style\n",
    "    # --- initialize data frame\n",
    "    data = {'group': list(),\n",
    "            'node ID': list(), \n",
    "            'diameter': list(), \n",
    "            'setting start ID': list(),\n",
    "            'leak start ID': list(), \n",
    "            'setting end ID': list(),\n",
    "            'leak end ID': list()}\n",
    "    df_information = pd.DataFrame(data=data)\n",
    "\n",
    "     # --- fill data frame\n",
    "    idx_info = 1\n",
    "    for idx_1 in df.index[:-2]:\n",
    "\n",
    "        # find index where leaky scenario starts\n",
    "        dia_end =  df.loc[idx_1,'dia']\n",
    "        dia_start =  df.loc[idx_1+1,'dia']\n",
    "        if dia_end != dia_start:\n",
    "\n",
    "            idx_start_scenario = idx_1+1\n",
    "\n",
    "            # find index where leak in leaky scenario starts and ends\n",
    "            for idx_2 in df.index[idx_start_scenario:-2]:\n",
    "\n",
    "                y_end = df.loc[idx_2,'y']\n",
    "                y_start = df.loc[idx_2 + 1,'y']\n",
    "                if y_end == 0 and y_start == 1:\n",
    "                    idx_start_leak = idx_2 + 1\n",
    "                if y_end == 1 and y_start == 0:\n",
    "                    idx_end_scenario = idx_2\n",
    "                    idx_end_leak = idx_2 + 1\n",
    "                    break\n",
    "                else:\n",
    "                    idx_end_scenario = idx_2\n",
    "                    idx_end_leak = idx_2\n",
    "\n",
    "            # access all information of the scenario at the end of the scenario\n",
    "            # as at the end, the leak is present\n",
    "            for group in ['y_group1','y_group2','y_group3']:\n",
    "                if df.loc[idx_end_scenario, group] == 1:\n",
    "                    df_information.loc[idx_info,'group'] = group[2:]\n",
    "        \n",
    "            df_information.loc[idx_info,'node ID'] = str(int(1 + (idx_info-1) / 3)) # fake nodeIDs\n",
    "            df_information.loc[idx_info,'diameter'] = df.loc[idx_end_scenario,'dia']\n",
    "            df_information.loc[idx_info,'setting start ID'] = idx_start_scenario\n",
    "            df_information.loc[idx_info,'leak start ID'] = idx_start_leak\n",
    "            df_information.loc[idx_info,'setting end ID'] = idx_end_scenario\n",
    "            df_information.loc[idx_info,'leak end ID'] = idx_end_leak\n",
    "\n",
    "            idx_info += 1\n",
    "\n",
    "    df_information['Y = 0 on left side'] = (df_information['leak start ID'] - 1) - df_information['setting start ID'] + 1\n",
    "    df_information['Y = 1'] = (df_information['leak end ID'] - 1) - df_information['leak start ID'] + 1\n",
    "    df_information['Y = 0 on right side'] = df_information['setting end ID'] - df_information['leak end ID'] + 1\n",
    "    df_information['Y = 0'] = df_information['Y = 0 on left side'] + df_information['Y = 0 on right side']\n",
    "\n",
    "    return df_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019f094-2769-4b19-990e-598f79101310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leaks = pd.read_csv('../2_DataGeneration/L-Town/data_leaks_LTown.csv')\n",
    "df_leaks = df_leaks.drop(['Unnamed: 0'], axis=1)\n",
    "df_leaks = df_leaks.rename(columns = {\"A\": \"y_group1\", \n",
    "                                      \"B\": \"y_group2\",\n",
    "                                      \"C\": \"y_group3\"})\n",
    "# transform m in cm\n",
    "df_leaks['dia'] = df_leaks['dia']*100\n",
    "df_information = LeakInformation(df_leaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ccf8b-422b-4d6b-a4ac-c9b4d44baa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9fa46-e96e-4e4a-805c-16f2f1d8fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8884a3-cbbd-41df-a023-c69c402d071d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f200539-82fa-4c8c-b561-1e5a01df183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./FairnessExploration_PipelineDefinition.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b062ee7-59f0-429d-8fcc-35bc6b285b5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pipeline application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399ae5e-9cde-4a4c-89e4-137c887e353a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f67b3-b0d2-4e09-b4c5-dc22d2c9d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifiers used per sensor node\n",
    "classifier = ThresholdClassification\n",
    "classifier_approx = ThresholdClassificationApproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505392c-36f5-44b4-ad26-0cfed1e6993b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# access node ids\n",
    "df_nodes = pd.read_csv('../2_DataGeneration/L-Town/data_nodes_LTown.csv')\n",
    "df_nodes = df_nodes.drop(['Unnamed: 0'], axis=1)\n",
    "node_ids = list(df_nodes.columns)\n",
    "#print('Given nodes: {}'.format(node_ids))\n",
    "\n",
    "# access sensor ids\n",
    "df_sensors = pd.read_csv('../2_DataGeneration/L-Town/data_leaks_LTown.csv')\n",
    "df_sensors = df_sensors.drop(['Unnamed: 0','y','A','B','C','dia'], axis=1)\n",
    "sensor_ids = list(df_sensors.columns)\n",
    "sensor_ids_n = ['n'+str(int(sensor)+1) for sensor in sensor_ids]\n",
    "print('Given sensors: {}'.format(sensor_ids_n))\n",
    "\n",
    "# access sensitive features\n",
    "sensitive_features = list(df_leaks.columns[33:36])\n",
    "print('Given sensitive features: {}'.format(sensitive_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25280567-94ae-43ff-91bc-0013a8b2427f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization - Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f6aaf-3b61-4037-a735-842a68e1a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_per_node = dict()\n",
    "for node in node_ids:\n",
    "    if df_nodes.loc[0,node] == 1.0:\n",
    "        groups_per_node[node] = 'group1'\n",
    "    if df_nodes.loc[1,node] == 2.0:\n",
    "        groups_per_node[node] = 'group2'\n",
    "    if df_nodes.loc[2,node] == 3.0:\n",
    "        groups_per_node[node] = 'group3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5f6e1-1cc4-487f-aa97-5dce7589a3a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wn_ltown = wntr.network.WaterNetworkModel('../1_FeatureGeneration/models/LTown.inp') \n",
    "\n",
    "plot_network_LTown(node_ids=node_ids,\n",
    "                   sensor_ids=sensor_ids_n,\n",
    "                   groups_per_node=groups_per_node,\n",
    "                   wn=wn_ltown,\n",
    "                   name='L-Town',\n",
    "                   save_figs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab802c8-b968-43e7-af07-63c3a917e284",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocessing for Classification - Compute Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27a428-835e-475c-b00d-7280ca68d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access residuals based on true data and predicted data\n",
    "X_clas = df_leaks.loc[:,sensor_ids]\n",
    "\n",
    "X_sen = df_leaks.loc[:,sensitive_features]\n",
    "y_clas = df_leaks.loc[:,['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdb0f2-bbd5-483c-b569-fd72c64f97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203e612-2c23-4da7-9989-38e8e1b98ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926e032-71f6-47b7-82fb-1f7e9a79ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_clas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2c81d-75dd-4b41-9fcd-d5c082a505c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization - True and Predicted Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5e2aa-4a06-4029-b0bb-7677db54b558",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot pressure *residuals*\n",
    "plot_data_per_setting(X_clas,\n",
    "                      df_information=df_information,\n",
    "                      sensor_ids=sensor_ids,\n",
    "                      node_ids=[str(x) for x in range(1,31)],\n",
    "                      diameters=[2.3],\n",
    "                      setting_ids=None,\n",
    "                      #thresholds={'3':0.5, '10':2, '23':0.2, '25':0.5},\n",
    "                      time_puffer=1000,\n",
    "                      show_legend=True,\n",
    "                      zoom_leak=True,\n",
    "                      print_report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea139ae-a4b1-4e6a-ba65-02080de8792e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification - Leak Detector(s)\n",
    "\n",
    "We now use the virtual sensors to predict the pressure even for times where a leak is active in the WDN. We make use of the residuals $|p_j(t_i) - f_j^r(p_{\\neq j}(t_i))| \\in \\mathbb{R}$ to define a threshold-based classifier that predicts whether a leak is active (1) or not (0) at time $t_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d368cbb-5f95-4c23-9eed-1dc882c48749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to store all results\n",
    "# which are visualized at the end\n",
    "results_fairness= dict()\n",
    "results_nofairness = dict()\n",
    "# define which fairness method\n",
    "# should improve which non-fairness method\n",
    "comparisons = {'DI+ACC-ndb-max':'ACC-ndb'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48841c0e-cccf-4638-83ff-195dca5aa2b9",
   "metadata": {},
   "source": [
    "**!!! Remark: !!!** Running the next blocks (\"Diameter = 1.9\", \"Diameter = 2.3\" and \"Diameter = 2.7\") takes 48-72 hrs. You can skip this part by loading the results in the \"Load Results\" block below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f461c-6a98-46e1-8f28-2332678fc279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Diameter = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d501f-516a-4df6-8e14-c9a3aff01a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the training and test data according to the diameter\n",
    "diameter = 1.9\n",
    "results = filter_diameter_LTown(X_clas, y_clas, X_sen, diameter=diameter, df_leaks=df_leaks)\n",
    "X_clas_train, X_clas_test, y_clas_train, y_clas_test, X_sen_train, X_sen_test = results\n",
    "print(X_sen_train.sum())\n",
    "print(X_sen_test.sum())\n",
    "\n",
    "# create dictionary to store all results \n",
    "# which are visualized at the end\n",
    "results_d5 = dict()\n",
    "results_fairness[diameter] = dict()\n",
    "results_nofairness[diameter] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f0881-a9d5-4f2c-a843-01c82cc1f2d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Choose hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc6fb6-a568-4dc2-9640-8e7fbae1dc1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_hyperparameter()\n",
    "model_clas.fit(X_clas_train, factor=0.25, print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d90ae-ae71-4193-aa87-d7d685d2b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_TPR = max(list(TPRs.values()))\n",
    "min_TPR = min(list(TPRs.values()))\n",
    "print('{} & {} & {} & {} & {} & {} & {}'.format(round(acc, 4),\n",
    "                                                round(max_TPR, 4),\n",
    "                                                round(min_TPR, 4),\n",
    "                                                round(di, 4),\n",
    "                                                round(eo, 4),\n",
    "                                                round((1-eo/max_TPR), 4),\n",
    "                                                round((1-di)*max_TPR, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5954a-135d-4a95-aeab-d3071c66cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d5[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ce56a-31ca-470c-b287-bc7e9e8725a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for ACC algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622384df-55ea-4bfe-b76c-09b3607796c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize ACC (ndb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce064a5c-5a6a-4d6a-81e3-7d188fdc10ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_optimizeACC_ndb(alias='ACC-ndb')\n",
    "model_clas.fit(X_clas_train, \n",
    "               X_sen_train,\n",
    "               y_clas_train,\n",
    "               start_thresholds=start_thresholds,\n",
    "               print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a3df3-58bf-4814-85b7-b2fcc7343342",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d5[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dabc3b-59ad-4965-a7d4-d18c7d4995db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for DI+ACC-ndb-max algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a988a-bb33-4489-9354-a94eb225bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,_,acc_best,_ = model_clas.score(X_clas_train, \n",
    "                                        y_clas_train,\n",
    "                                        print_all_scores=False)\n",
    "acc_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2227ace-6157-4a2f-8f56-20a835cdfe41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize DI (ndb., max-barrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2a3eb-f65f-4566-8c29-eff1c09638a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "# model_clas.fit(X_clas_train,\n",
    "#                X_sen_train,\n",
    "#                y_clas_train,\n",
    "#                start_thresholds=start_thresholds,\n",
    "#                mu=100, #100\n",
    "#                lamb=0.02, #0.00, 0.01, 0.02!, 0.03, ..., 0.33\n",
    "#                barrier='max',\n",
    "#                acc_best=acc_best,\n",
    "#                print_coeff=True)\n",
    "# acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246b62d-ffe0-4e38-bf59-f41de14eece9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- specify hyperparameters and model class\n",
    "start_hyper = 0.33\n",
    "model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "\n",
    "# --- define constant for stopping criterium\n",
    "comparison_algo = comparisons[model_clas.alias]\n",
    "di_nofairness = results_nofairness[diameter][comparison_algo]['di']\n",
    "print('disparate impact of approx. {} '\\\n",
    "      'from {} algorithm is used as a stopping criterium.'.format(round(di_nofairness,5),\n",
    "                                                                        comparison_algo))\n",
    "\n",
    "# --- test model for different hyperparameters\n",
    "Cs = [round(start_hyper-i*0.01,2) for i in range(0,40) if round(start_hyper-i*0.01,2)>=0]\n",
    "print('\\nHyperparameters to test:\\n', Cs)\n",
    "results_fairness[diameter][model_clas.alias] = dict()\n",
    "results_fairness[diameter][model_clas.alias]['ACCs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['EOs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['DIs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['Lambdas'] = list()\n",
    "for lamb in Cs:\n",
    "    print('\\nlambda:', lamb)\n",
    "    # --- train model for fixed hyperparameters\n",
    "    model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "    model_clas.fit(X_clas_train,\n",
    "                   X_sen_train,\n",
    "                   y_clas_train,\n",
    "                   start_thresholds=start_thresholds,\n",
    "                   mu=100, #100\n",
    "                   lamb=lamb, #0.00, 0.01, 0.02!, 0.03, ..., 0.33\n",
    "                   barrier='max',\n",
    "                   acc_best=acc_best,\n",
    "                   print_coeff=False)\n",
    "    # --- evaluate model for fixed hyperparameters\n",
    "    acc,eo,di,TPRs = evaluate(model_clas)\n",
    "    # --- store evaluation until model is as unfair as comparison model\n",
    "    if di <= di_nofairness:\n",
    "        print('\\nHyperparameter {} and larger were not used'.format(lamb))\n",
    "        break\n",
    "    results_d5[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "    results_fairness[diameter][model_clas.alias]['ACCs'].append(acc)\n",
    "    results_fairness[diameter][model_clas.alias]['EOs'].append(eo)\n",
    "    results_fairness[diameter][model_clas.alias]['DIs'].append(di)\n",
    "    results_fairness[diameter][model_clas.alias]['Lambdas'].append(lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0df703-ac2d-4a24-af48-aebfbf894baf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Diameter = 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886c5c8-fe58-4892-a275-fd475c173aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the training and test data according to the diameter\n",
    "diameter = 2.3\n",
    "results = filter_diameter_LTown(X_clas, y_clas, X_sen, diameter=diameter, df_leaks=df_leaks)\n",
    "X_clas_train, X_clas_test, y_clas_train, y_clas_test, X_sen_train, X_sen_test = results\n",
    "print(X_sen_train.sum())\n",
    "print(X_sen_test.sum())\n",
    "\n",
    "# create dictionary to store all results \n",
    "# which are visualized at the end\n",
    "results_d10 = dict()\n",
    "results_fairness[diameter] = dict()\n",
    "results_nofairness[diameter] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c830f0-6003-4cd5-8079-8be700f2462e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Choose hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd04bc2-0892-484a-a216-2518ed711d70",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_hyperparameter()\n",
    "model_clas.fit(X_clas_train, factor=0.19, print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070d658-94f3-42f6-9c6c-be323bdfcec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_TPR = max(list(TPRs.values()))\n",
    "min_TPR = min(list(TPRs.values()))\n",
    "print('{} & {} & {} & {} & {} & {} & {}'.format(round(acc, 4),\n",
    "                                                round(max_TPR, 4),\n",
    "                                                round(min_TPR, 4),\n",
    "                                                round(di, 4),\n",
    "                                                round(eo, 4),\n",
    "                                                round((1-eo/max_TPR), 4),\n",
    "                                                round((1-di)*max_TPR, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3561d3e-c8e8-478b-8858-d21d2b340ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d10[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a75d2-8ec9-4fd1-82f7-965405d88f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for ACC algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48fddb-9b92-4de6-a5b3-96d460048031",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize ACC (ndb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8b8c8-0da3-48bd-8caa-0c8fe77e394a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_optimizeACC_ndb(alias='ACC-ndb')\n",
    "model_clas.fit(X_clas_train, \n",
    "               X_sen_train,\n",
    "               y_clas_train,\n",
    "               start_thresholds=start_thresholds,\n",
    "               print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b870bc0-df9d-410c-9e1b-e954915c5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d10[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f741043-280e-428e-9118-dc77f7c89d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for DI+ACC-ndb-max algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87869321-9d0f-4a61-b3cd-40e893f340ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,_,acc_best,_ = model_clas.score(X_clas_train, \n",
    "                                        y_clas_train,\n",
    "                                        print_all_scores=False)\n",
    "acc_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227f30c-6ab0-4e8b-90b3-62191b6115df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize DI (ndb., max-barrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0c1c5-2326-4b21-b892-0f93d9f2d062",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "#model_clas.fit(X_clas_train,\n",
    "#               X_sen_train,\n",
    "#               y_clas_train,\n",
    "#               start_thresholds=start_thresholds,\n",
    "#               mu=100, #100\n",
    "#               lamb=0.0, #0.00!, 0.01, ..., 0.46\n",
    "#               barrier='max',\n",
    "#               acc_best=acc_best,\n",
    "#               print_coeff=True)\n",
    "#acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc63e5-dbbd-4a33-b1d0-7151d893a4fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- specify hyperparameters and model class\n",
    "start_hyper = 0.46\n",
    "model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "\n",
    "# --- define constant for stopping criterium\n",
    "comparison_algo = comparisons[model_clas.alias]\n",
    "di_nofairness = results_nofairness[diameter][comparison_algo]['di']\n",
    "print('disparate impact of approx. {} '\\\n",
    "      'from {} algorithm is used as a stopping criterium.'.format(round(di_nofairness,5),\n",
    "                                                                        comparison_algo))\n",
    "\n",
    "# --- test model for different hyperparameters\n",
    "Cs = [round(start_hyper-i*0.01,2) for i in range(0,50) if round(start_hyper-i*0.01,2)>=0]\n",
    "print('\\nHyperparameters to test:\\n', Cs)\n",
    "results_fairness[diameter][model_clas.alias] = dict()\n",
    "results_fairness[diameter][model_clas.alias]['ACCs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['EOs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['DIs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['Lambdas'] = list()\n",
    "for lamb in Cs:\n",
    "    print('\\nlambda:', lamb)\n",
    "    # --- train model for fixed hyperparameters\n",
    "    model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "    model_clas.fit(X_clas_train,\n",
    "                   X_sen_train,\n",
    "                   y_clas_train,\n",
    "                   start_thresholds=start_thresholds,\n",
    "                   mu=100, #100\n",
    "                   lamb=lamb, #0.00!, 0.01, ..., 0.46\n",
    "                   barrier='max',\n",
    "                   acc_best=acc_best,\n",
    "                   print_coeff=False)\n",
    "    # --- evaluate model for fixed hyperparameters\n",
    "    acc,eo,di,TPRs = evaluate(model_clas)\n",
    "    # --- store evaluation until model is as unfair as comparison model\n",
    "    if di <= di_nofairness:\n",
    "        print( \n",
    "            '\\nHyperparameter {} and larger were not used'.format(lamb))\n",
    "        break\n",
    "    results_d10[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "    results_fairness[diameter][model_clas.alias]['ACCs'].append(acc)\n",
    "    results_fairness[diameter][model_clas.alias]['EOs'].append(eo)\n",
    "    results_fairness[diameter][model_clas.alias]['DIs'].append(di)\n",
    "    results_fairness[diameter][model_clas.alias]['Lambdas'].append(lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe83b3-78ee-46c2-9a02-8fcaa157e767",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Diameter = 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d5f2b-0404-4c44-8bd0-be8ad9b54193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the training and test data according to the diameter\n",
    "diameter = 2.7\n",
    "results = filter_diameter_LTown(X_clas, y_clas, X_sen, diameter=diameter, df_leaks=df_leaks)\n",
    "X_clas_train, X_clas_test, y_clas_train, y_clas_test, X_sen_train, X_sen_test = results\n",
    "print(X_sen_train.sum())\n",
    "print(X_sen_test.sum())\n",
    "\n",
    "# create dictionary to store all results \n",
    "# which are visualized at the end\n",
    "results_d15 = dict()\n",
    "results_fairness[diameter] = dict()\n",
    "results_nofairness[diameter] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd460bd-1816-4c00-98c6-54d39d3be69e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Method: Choose hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f87a7-d131-41e8-9d82-38efad0747fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_hyperparameter()\n",
    "model_clas.fit(X_clas_train, factor=0.15, print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c82fbd-cf7a-4892-81a0-9bd9a4bbc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_TPR = max(list(TPRs.values()))\n",
    "min_TPR = min(list(TPRs.values()))\n",
    "print('{} & {} & {} & {} & {} & {} & {}'.format(round(acc, 4),\n",
    "                                                round(max_TPR, 4),\n",
    "                                                round(min_TPR, 4),\n",
    "                                                round(di, 4),\n",
    "                                                round(eo, 4),\n",
    "                                                round((1-eo/max_TPR), 4),\n",
    "                                                round((1-di)*max_TPR, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ce34a-29ed-46c1-bdbb-ca127185895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d15[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908abac-3e0b-4b15-8877-693eff180e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for ACC algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e04785-8ab4-4adb-a47f-4100b59a48e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize ACC (ndb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bcc63-5bcf-440b-8c2b-801487b10599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_clas = ETC_optimizeACC_ndb(alias='ACC-ndb')\n",
    "model_clas.fit(X_clas_train, \n",
    "               X_sen_train,\n",
    "               y_clas_train,\n",
    "               start_thresholds=start_thresholds,\n",
    "               print_coeff=True)\n",
    "acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc39ffa-9f49-4f9b-b75c-b024f17ddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d15[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "results_nofairness[diameter][model_clas.alias] = dict()\n",
    "results_nofairness[diameter][model_clas.alias]['acc'] = acc\n",
    "results_nofairness[diameter][model_clas.alias]['eo'] = eo\n",
    "results_nofairness[diameter][model_clas.alias]['di']= di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d7398-bf41-479c-8b42-305bcf3974d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the starting point for DI+ACC-ndb-max algorithm\n",
    "start_thresholds = model_clas.thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc52018-80ae-4bb0-89c3-98fefa84c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,_,acc_best,_ = model_clas.score(X_clas_train, \n",
    "                                        y_clas_train,\n",
    "                                        print_all_scores=False)\n",
    "acc_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4998165-49c3-4ec3-a513-c28b7573cae9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Method: Optimize DI (ndb., max-barrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289733c9-90a4-465c-aa3b-53a2a31016e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "#model_clas.fit(X_clas_train,\n",
    "#               X_sen_train,\n",
    "#               y_clas_train,\n",
    "#               start_thresholds=start_thresholds,\n",
    "#               mu=100, #100\n",
    "#               lamb=0.01, #0.0, 0.1!, 0.2 ..., 0.5\n",
    "#               barrier='max',\n",
    "#               acc_best=acc_best,\n",
    "#               print_coeff=True)\n",
    "#acc,eo,di,TPRs = evaluate(model_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643fb93-10f0-43b8-b65b-683b4ca246a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- specify hyperparameters and model class\n",
    "start_hyper = 0.5\n",
    "model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "\n",
    "# --- define constant for stopping criterium\n",
    "comparison_algo = comparisons[model_clas.alias]\n",
    "di_nofairness = results_nofairness[diameter][comparison_algo]['di']\n",
    "print('disparate impact of approx. {} '\\\n",
    "      'from {} algorithm is used as a stopping criterium.'.format(round(di_nofairness,5),\n",
    "                                                                        comparison_algo))\n",
    "\n",
    "# --- test model for different hyperparameters\n",
    "Cs = [round(start_hyper-i*0.01,2) for i in range(0,60) if round(start_hyper-i*0.01,2)>=0]\n",
    "print('\\nHyperparameters to test:\\n', Cs)\n",
    "results_fairness[diameter][model_clas.alias] = dict()\n",
    "results_fairness[diameter][model_clas.alias]['ACCs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['EOs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['DIs'] = list()\n",
    "results_fairness[diameter][model_clas.alias]['Lambdas'] = list()\n",
    "for lamb in Cs:\n",
    "    print('\\nlambda:', lamb)\n",
    "    # --- train model for fixed hyperparameters\n",
    "    model_clas = ETC_optimizeDI_ndb(alias='DI+ACC-ndb-max')\n",
    "    model_clas.fit(X_clas_train,\n",
    "                   X_sen_train,\n",
    "                   y_clas_train,\n",
    "                   start_thresholds=start_thresholds,\n",
    "                   mu=100, #100\n",
    "                   lamb=lamb, #0.0, 0.1!, 0.2 ..., 0.5\n",
    "                   barrier='max',\n",
    "                   acc_best=acc_best,\n",
    "                   print_coeff=False)\n",
    "    # --- evaluate model for fixed hyperparameters\n",
    "    acc,eo,di,TPRs = evaluate(model_clas)\n",
    "    # --- store evaluation until model is as unfair as comparison model\n",
    "    if di <= di_nofairness:\n",
    "        print('\\nHyperparameter {} and larger were not used'.format(lamb))\n",
    "        break\n",
    "    results_d15[model_clas] = {'acc':acc,'eo':eo,'di':di,'TPRs':TPRs}\n",
    "    results_fairness[diameter][model_clas.alias]['ACCs'].append(acc)\n",
    "    results_fairness[diameter][model_clas.alias]['EOs'].append(eo)\n",
    "    results_fairness[diameter][model_clas.alias]['DIs'].append(di)\n",
    "    results_fairness[diameter][model_clas.alias]['Lambdas'].append(lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be00339-f635-4468-8a42-23cf09cbd09a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Store Results \n",
    "(as computation time of the previous blocks is about 48-72hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dde5e-1a4e-4ebb-a809-1f5312dfb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionaries to pkl file\n",
    "with open('results_LTown_d5.pkl', 'wb') as file:\n",
    "    pickle.dump(results_d5, file)\n",
    "with open('results_LTown_d10.pkl', 'wb') as file:\n",
    "    pickle.dump(results_d10, file)\n",
    "with open('results_LTown_d15.pkl', 'wb') as file:\n",
    "    pickle.dump(results_d15, file)\n",
    "with open('results_LTown_results_fairness.pkl', 'wb') as file:\n",
    "    pickle.dump(results_fairness, file)\n",
    "with open('results_LTown_results_nofairness.pkl', 'wb') as file:\n",
    "    pickle.dump(results_nofairness, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87ee57-2fe5-4be4-88ed-73d7b9f5374d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Results\n",
    "(in case you do not want to run the code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429d18e-e3a3-4fd2-b29b-b7d61c873e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary from pkl file\n",
    "with open('./results_L-Town/results_L-Town_d5.pkl', 'rb') as file:\n",
    "    results_d5 = pickle.load(file)\n",
    "with open('./results_L-Town/results_L-Town_d10.pkl', 'rb') as file:\n",
    "    results_d10 = pickle.load(file)\n",
    "with open('./results_L-Town/results_L-Town_d15.pkl', 'rb') as file:\n",
    "    results_d15 = pickle.load(file)\n",
    "with open('./results_L-Town/results_L-Town_results_fairness.pkl', 'rb') as file:\n",
    "    results_fairness = pickle.load(file)\n",
    "with open('./results_L-Town/results_L-Town_results_nofairness.pkl', 'rb') as file:\n",
    "    results_nofairness = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce454f9c-5ec7-4faa-ba58-c5f695af13e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79678d6-02a1-465b-9509-c5880ff5ab18",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "aliase = ['H','ACC-ndb','DI+ACC-ndb-max']\n",
    "results_d5_final = dict()\n",
    "for key in results_d5.keys():\n",
    "    if key.alias in aliase:\n",
    "        results_d5_final[key] = results_d5[key]\n",
    "        \n",
    "df1, df2, df3, fig_d5 = graphics_bars(results_d5_final,\n",
    "                                      save_figs_d=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48aa37-9129-4d8c-9c4d-d00d3933d417",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "aliase = ['H','ACC-ndb','DI+ACC-ndb-max']\n",
    "results_d10_final = dict()\n",
    "for key in results_d10.keys():\n",
    "    if key.alias in aliase:\n",
    "        results_d10_final[key] = results_d10[key]\n",
    "        \n",
    "df1, df2, df3, fig_d10 = graphics_bars(results_d10_final,\n",
    "                                       save_figs_d=2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32489682-cfc2-4dbf-9ace-1d9759929c21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "aliase = ['H','ACC-ndb','DI+ACC-ndb-max']\n",
    "results_d15_final = dict()\n",
    "for key in results_d15.keys():\n",
    "    if key.alias in aliase:\n",
    "        results_d15_final[key] = results_d15[key]\n",
    "\n",
    "df1, df2, df3, fig_d15 = graphics_bars(results_d15_final,\n",
    "                                       save_figs_d=2.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588bd82-aeee-412c-b16f-22c970b5e7fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphics_scatter(results_fairness, \n",
    "                 results_nofairness,\n",
    "                 comparisons,\n",
    "                 horizontal=True,\n",
    "                 save_figs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289c4b5-ee88-4f84-9926-ef55fe439649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just some work-around to keep the figure size equal to the Hanoi figures\n",
    "results_fairness_copy = copy.deepcopy(results_fairness)\n",
    "for diameter in results_fairness_copy.keys():\n",
    "    for alias in ['Alias 1', 'Alias 2', 'Alias 3']:\n",
    "        results_fairness_copy[diameter][alias] = results_fairness[diameter]['DI+ACC-ndb-max'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8d672-a01e-41e8-ac2e-699c9c080e97",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphics_lines(results_fairness_copy,\n",
    "               results_nofairness,\n",
    "               comparisons,\n",
    "               columns='diameters',\n",
    "               with_eo=True,\n",
    "               save_figs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cd5fa-531c-41f2-b810-457bfa33a1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
